version: '3'

x-spark-common: &spark-common
  image: bitnami/spark:3.5.0
  volumes:
    - ./jobs:/opt/bitnami/spark/jobs
  networks:
    - flink-algorithmic-trading

services:
  redpanda-1:
    image: docker.redpanda.com/redpandadata/redpanda:v23.1.8
    container_name: redpanda-1
    command:
      - redpanda
      - start
      - --smp
      - '1'
      - --reserve-memory
      - 0M
      - --overprovisioned
      - --node-id
      - '1'
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda-1:29092,OUTSIDE://localhost:9092
      - --pandaproxy-addr
      - PLAINTEXT://0.0.0.0:28082,OUTSIDE://0.0.0.0:8082
      - --advertise-pandaproxy-addr
      - PLAINTEXT://redpanda-1:28082,OUTSIDE://localhost:8082
      - --rpc-addr
      - 0.0.0.0:33145
      - --advertise-rpc-addr
      - redpanda-1:33145
    ports:
      - 8082:8082
      - 9092:9092
      - 28082:28082
      - 29092:29092
    networks:
      - flink-algorithmic-trading

  redpanda-2:
     image: docker.redpanda.com/redpandadata/redpanda:v23.1.8
     container_name: redpanda-2
     command:
       - redpanda
       - start
       - --smp
       - '1'
       - --reserve-memory
       - 0M
       - --overprovisioned
       - --node-id
       - '2'
       - --seeds
       - redpanda-1:33145
       - --kafka-addr
       - PLAINTEXT://0.0.0.0:29093,OUTSIDE://0.0.0.0:9093
       - --advertise-kafka-addr
       - PLAINTEXT://redpanda-2:29093,OUTSIDE://localhost:9093
       - --pandaproxy-addr
       - PLAINTEXT://0.0.0.0:28083,OUTSIDE://0.0.0.0:8083
       - --advertise-pandaproxy-addr
       - PLAINTEXT://redpanda-2:28083,OUTSIDE://localhost:8083
       - --rpc-addr
       - 0.0.0.0:33146
       - --advertise-rpc-addr
       - redpanda-2:33146
     ports:
       - 8083:8083
       - 9093:9093
       - 28083:28083
       - 29093:29093
     networks:
       - flink-algorithmic-trading

  redpanda-console:
    image: docker.redpanda.com/redpandadata/console:v2.2.4
    container_name: redpanda-console
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda-1:29092", "redpanda-2:29092"]
          schemaRegistry:
            enabled: false
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://redpanda-1:9644", "http://redpanda-2:9644"]
        connect:
          enabled: false
    ports:
      - 8080:8080
    depends_on:
      - redpanda-1
      - redpanda-2
    networks:
      - flink-algorithmic-trading

  jobmanager:
    container_name: jobmanager
    build:
      context: .
      dockerfile: Dockerfile-sql
    ports:
      - 8081:8081
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
    networks:
      - flink-algorithmic-trading

  taskmanager:
    container_name: taskmanager
    build:
      context: .
      dockerfile: Dockerfile-sql
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 20
    networks:
      - flink-algorithmic-trading

  sql-client:
    container_name: sql-client
    build:
      context: .
      dockerfile: Dockerfile-sql
    command:
      - /opt/flink/bin/sql-client.sh
      - embedded
      - -l
      - /opt/sql-client/lib
    depends_on:
      - jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager
    networks:
      - flink-algorithmic-trading
  
  spark-master:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  spark-worker: &spark-worker-image
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  spark-worker-2:
    <<: *spark-worker-image

  spark-worker-3:
    <<: *spark-worker-image

  cassandra_db:
    image: cassandra:latest
    container_name: cassandra_stock
    hostname: cassandra
    ports:
      - "9042:9042"
    environment:
      - MAX_HEAP_SIZE=512M
      - HEAP_NEWSIZE=100M
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    networks:
      - flink-algorithmic-trading
      
networks:
  flink-algorithmic-trading:
    driver: bridge
